<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<title>Satoshi Ikehata</title>
	
<style type="text/css">
<!--
	announce {
            font-family: Arial, sans-serif;
            text-align: center;
            padding: 50px;
        }
        .announcement {
            background-color: #ffcc00;
            padding: 20px;
            border-radius: 10px;
            display: inline-block;
            font-size: 24px;
            font-weight: bold;
            color: #333;
        }
        .apply-link {
            display: block;
            margin-top: 20px;
            font-size: 20px;
            color: #fff;
            background-color: #007bff;
            padding: 10px 20px;
            border-radius: 5px;
            text-decoration: none;
        }
        .apply-link:hover {
            background-color: #0056b3;
        }
body {
	background: #FFFFFF;
	margin: 0;
	padding: 0;
	color: #000;
	font-family: "ヒラギノ角ゴ Pro W3", "Hiragino Kaku Gothic Pro", "メイリオ", Meiryo, Osaka, "ＭＳ Ｐゴシック", "MS P Gothic", sans-serif;
	font-size: 12px;
	line-height: 1.4;
}

ul, ol, dl {
	padding: 0;
	margin: 0;
}
.news_table {
	margin-left: 20px;
	margin-top: 20px;
	margin-bottom: 20px;
}
h1, h2, h3, h4, h5, h6, p {
	margin-top: 0;
	padding-right: 15px;
	padding-left: 15px;
}
a img {
	border: none;
}


a:link {
	color:#414958;
	text-decoration: underline;
}
a:visited {
	color: #4E5869;
	text-decoration: underline;
}
a:hover, a:active, a:focus {
	text-decoration: none;
}


.container {
	width: 80%;
	max-width: 1260px;
	min-width: 780px;
	background: #FFF;
	margin: 0 auto;
}


.header {
	background-color: #6F7D94;
	background-image: url(hishi01.gif);
}

.sidebar1 {
	float: left;
	width: 10%;
	padding-bottom: 10px;
	background-color: #FFF;
}
.session2{
	color: #FFF;
	font-size: 12px;
	background-color: #FFF;
	text-align: left;

}
.session {
	font-size: 12px;
	background-color: #CCC;
	text-align: left;
}
.content {
	padding: 10px 0;
	width: 80%;
	float: left;
}

.content ul, .content ol {
	padding: 0 15px 15px 40px;
}


ul.nav {
	list-style: none;
	border-top: 1px solid #666;
	margin-bottom: 15px;
}
ul.nav li {
	border-bottom: 1px solid #666;
}
ul.nav a, ul.nav a:visited {
	padding: 5px 5px 5px 15px;
	display: block;
	text-decoration: none;
	background: #8090AB;
	color: #000;
}
ul.nav a:hover, ul.nav a:active, ul.nav a:focus {
	background: #6F7D94;
	color: #FFF;
}

.footer {
	padding: 10px 0;
	background: #001F8C;
	position: relative;
	clear: both;
	color: #FFF;
}

.fltrt {
	float: right;
	margin-left: 8px;
}
.fltlft {
	float: left;
	margin-right: 8px;
}
.clearfloat {
	clear:both;
	height:0;
	font-size: 1px;
	line-height: 0px;
}
.image_float_left {
	float: left;
	margin-right: 30px;
	margin-bottom: 30px;
}
.table_float {
	width: 50%;
}
.side_table {
	margin-top: 50px;
	margin-right: 10px;
	margin-left: 10px;
}
-->
</style>
</head>

<body>

<div class="container">
  <div class="header"><a href="#"><img src="" name="Insert_logo" width="0%" height="25" id="Insert_logo" ; display:block;" /></a>
    <!-- end .header --></div>

  <div class="sidebar1">
    <table width="10%" border="0" class="side_table">
  <tr>
    <td><!-- Satoshi Ikehata --></td>
  </tr>
  <tr>
    <td><!-- Projects--></td>
  </tr>
  <tr>
    <td><!--Codes--></td>
  </tr>
  </table>

    <!-- end .sidebar1 --></div>
  <div class="content">
    <h1>Welcome to Satoshi Ikehata's Home Page</h1>
    <p><img src="my_picture.jpg" width="225" height="150" class="image_float_left" /></p>
    <table width="60%" border="0" class="table_float">
      <tr>
        <td align="left"><strong>Satoshi Ikehata, PhD</strong></td>
      </tr>
      <tr>
        <td align="left">Associate Proffesor in  <a href="https://www.nii.ac.jp/en/" target="_blank">National Institute of Informatics (Since 2017)</a>
			</td>
      </tr>
      <tr>
	  <td align="left">Specially Appointed Associate Proffesor at <a href="https://d-itlab.c.titech.ac.jp/miru2022event//" target="_blank">Recognition and Learning Algoritym Laboratory in Tokyo Tech (Since 2023)</a>
      </tr>
      <tr>
	  <td align="left">Visiting Researcher at  <a href="http://www.hal.t.u-tokyo.ac.jp/lab/en/index_1.xhtml" target="_blank">Aizawa-Yamakata-Matsui Lab in UTokyo (Since 2020)</a>
      </tr>
	  <tr>
        <td align="left"> Address: 2-1-2 Hitotsubashi, Chiyoda-ku, Tokyo 101-8430<br /></td>
      </tr>
      <tr>
        <td align="left">E-mail: sikehata@nii.ac.jp</td>
      </tr>
      <tr>
        <td height="27" align="left"> (<a href="cv.pdf" target="_blank">curriculum vitae</a>) </td>
      </tr>
    </table>
<announce>
    <div class="announcement">
        I am currently looking for talented Ph.D students at SOKENDAI and interns at NII (NII International Internship Program, 2025 1st Call Applications must be sent to me by the end of March 2025, at 17:00 JST. Please see more detials 
        <strong><a href="https://www.nii.ac.jp/en/about/international/mouresearch/internship2025-1/">NII International Internship Program: 2025 1st Call</a></strong>
　　    <strong><a href="https://https://www.soken.ac.jp/en/prog/informatics/" class="apply-link">SOKENDAI Ph.D Program</a></strong>
	    
    </div>
</announce>
<p>&nbsp;</p>
<p>&nbsp;</p>
<h2 class="session">About me</h2>
<p align="left">
<p>- From June 2014 to November 2016, I was a post-doc researcher in Washington University in St. Louis and worked with <a href='http://www.cse.wustl.edu/~furukawa/', target = "_blank">Dr. Yasutaka Furukawa</a>.
<p>- I got my Ph. D in 2014 and MS in 2011 in University of tokyo under the supervision of <a href="http://www.hal.t.u-tokyo.ac.jp/~aizawa/index.html" target="_blank">Prof. Kiyoharu Aizawa</a>. </p>
<p>- I got my BA of Psychology from the University of Tokyo in 2009 under the supervision of <a href="http://www.l.u-tokyo.ac.jp/psy/sato_ind/index.html" target="_blank">Prof. Takao Sato</a>. </p>
<p>- I worked for<a href="http://research.microsoft.com/en-us/groups/vc/" target="_blank"> Visual Computing Group</a> at Microsoft Research Asia as a visiting student in 2011, supervised by <a href="http://research.microsoft.com/en-us/people/yasumat/" target="_blank">Dr. Yasuyuki Matsushita</a>. </p>

<h2 class="session">NEWS</h2>
<table width="90%" border="0" class="news_table">
<tr>
	 <td width="12%">6/2022 </td>
	 <td width="88%">Project website of CVPR2023 work is now available.</td>
</tr>
	  
<tr>
	 <td width="12%">6/2022 </td>
	 <td width="88%">Project website of CVPR2022 work is now available.</td>
</tr>

<tr>
	 <td width="12%">11/2021 </td>
	 <td width="88%">Source code of BMVC2021 work is now available.</td>
</tr>

<tr>
	 <td width="12%">8/2018 </td>
	 <td width="88%">Source code of ECCV2018 work is now available.</td>
 </tr>
<tr>
	 <td width="12%">7/2014 </td>
	 <td width="88%">Project page of ICCV2015 work is now available.</td>
 </tr>
<tr>
 	 <td width="12%">7/2014 </td>
 	 <td width="88%">Souce code of our TPAMI2014 work is now available.</td>
</tr>
<tr>
	 <td width="12%">7/2014 </td>
	 <td width="88%">Souce code of our CVPR2014 work is now available.</td>
 </tr>
 <tr>
    <td width="12%">7/2012 </td>
    <td width="88%">Souce code of our CVPR2012 work is now available.</td>
  </tr>
  <tr>
    <td>3/2012</td>
    <td>Open a new home page.</td>
  </tr>
</table>
<h3 class="session">Class (SOKENDAI)</h3>
	<p> Fall 2020: <a href="mediaprocessing2020.html" target="_blank">Fundamentals of Media Processing</a></p>
<h3 class="session">Research Interests</h3>
    <p>3D Scene Reconstruction, Time-of-flight Imaging, Image Super-resolution, Virtual and Augmented Reality, Human Cognition and Perception</p>

<h4 class="session">Selected Papers</h4>
Full publication list is available at <a href="https://researchmap.jp/sikehata?lang=en" target="_blank">researchmap</a>.
<table width="100%" border="0">

<tr>
    <td><img src="fig_icip2024.png" width="192" class="image_float_left" /> </td>
    <td><strong>
Gumble-NeRF: Representing Unseen Objects as Part-compositional Neural Radiance Feilds. </strong><br />
    <span id="ctl00_cph_paperSummary_gvPaperSummary_ctl05_PaperTitleLabel1"><span id="ctl00_cph_paperSummary_gvPaperSummary_ctl04_PaperTitleLabel2">  Yusuke Sekikawa, Chingwei Hsu, Satoshi Ikehata, Rei Kawakami, Ikuro Sato. In proceedings of International Conference on Image Processing (ICIP), 2024.　</td>
  </tr> </span></td>
</tr>
	
<tr>
    <td><img src="fig_eccv2024_ps.png" width="192" class="image_float_left" /> </td>
    <td><strong>Physics-Free Spectrally Multiplexed Photometric Stereo under Unknown Spectral Composition. </strong><br />
    <span id="ctl00_cph_paperSummary_gvPaperSummary_ctl05_PaperTitleLabel1"><span id="ctl00_cph_paperSummary_gvPaperSummary_ctl04_PaperTitleLabel2">  Satoshi Ikehata, 
	    Yuta Asano. In proceedings of European Conference on Computer Vision (ECCV), 2024 (accepted as an oral presentation).  　</td>
  </tr> </span></td>
</tr>

<tr>
    <td><img src="fig_eccv2024_relight.png" width="192" class="image_float_left" /> </td>
    <td><strong>Towards Single-Shot Photometric Stereo through Material Estimation and Relighting. </strong><br />
    <span id="ctl00_cph_paperSummary_gvPaperSummary_ctl05_PaperTitleLabel1"><span id="ctl00_cph_paperSummary_gvPaperSummary_ctl04_PaperTitleLabel2">  Ashish Tiwari
 , Satoshi Ikehata, Shanmuganathan Raman. In proceedings of European Conference on Computer Vision (ECCV), 2024.</td>
  </tr> </span></td>
</tr>

<tr>
    <td><img src="fig_cvpr2024.png" width="192" class="image_float_left" /> </td>
    <td><strong>Entity-NeRF: Detecting and Removing Moving Entities in Urban Scenes. </strong><br />
    <span id="ctl00_cph_paperSummary_gvPaperSummary_ctl05_PaperTitleLabel1"><span id="ctl00_cph_paperSummary_gvPaperSummary_ctl04_PaperTitleLabel2">  Takashi Otonari, Satoshi Ikehata, Kiyoharu Aizawa.   In proceedings of CVF/IEEE Computer Vision and Pattern Recognition (CVPR), 2024　(<a href="https://arxiv.org/pdf/2403.16141" target="_blank">paper (arxiv)</a>, <a href="https://otonari726.github.io/entitynerf/" target="_blank">website</a>).</td>
  </tr> </span></td>
</tr>

<tr>
    <td><img src="fig_icip2022_od.png" width="192" class="image_float_left" /> </td>
    <td><strong>Field-of-View IoU for Object Detection in 360° Images. </strong><br />
    <span id="ctl00_cph_paperSummary_gvPaperSummary_ctl05_PaperTitleLabel1"><span id="ctl00_cph_paperSummary_gvPaperSummary_ctl04_PaperTitleLabel2">  Miao Cao, Satoshi Ikehata, Kiyoharu Aizawa.   IEEE Transactions on Image Procession (TIP), 2023 (<a href="https://ieeexplore.ieee.org/document/10190308" target="_blank">paper</a>). </span></td>
  </tr> </span></td>
</tr>
	
<tr>
    <td><img src="cvpr2023.png" width="192" class="image_float_left" /> </td>
    <td><strong>Scalable, Detailed and Mask-free Universal Photometric Stereo</strong><br />
    <span id="ctl00_cph_paperSummary_gvPaperSummary_ctl05_PaperTitleLabel1"><span id="ctl00_cph_paperSummary_gvPaperSummary_ctl04_PaperTitleLabel2">  Satoshi Ikehata.  In proceedings of CVF/IEEE Computer Vision and Pattern Recognition (CVPR), 2023. (accepted as a highlight paper, 2.5%) (<a href="https://arxiv.org/abs/2303.15724" target="_blank">paper (arxiv)</a>, <a href="https://github.com/satoshi-ikehata/SDM-UniPS-CVPR2023" target="_blank">code (github)</a>)<tr>
</tr>
	  
<tr>
    <td><img src="fig_bmvc2022.png" width="192" class="image_float_left" /> </td>
    <td><strong>Non-uniform Sampling Strategies for NeRF on 360 images  </strong><br />
    <span id="ctl00_cph_paperSummary_gvPaperSummary_ctl05_PaperTitleLabel1"><span id="ctl00_cph_paperSummary_gvPaperSummary_ctl04_PaperTitleLabel2">  Takashi Otonari, Satoshi Ikehata, Kiyoharu Aizawa.  In proceedings of British Machine Vision Conference (BMVC), 2022.<tr>
</tr>

<tr>
    <td><img src="fig_access2022.png" width="192" class="image_float_left" /> </td>
    <td><strong>Saliency-Based Multiple Region of Interest Detection From a Single 360° Image  </strong><br />
    <span id="ctl00_cph_paperSummary_gvPaperSummary_ctl05_PaperTitleLabel1"><span id="ctl00_cph_paperSummary_gvPaperSummary_ctl04_PaperTitleLabel2">  Yuki Sawabe, Satoshi Ikehata, Kiyoharu Aizawa. In IEEE Access, vol. 10, pp. 89124-89133, 2022.<tr>
</tr>

<tr>
    <td><img src="fig_icip2022_ps.jpg" width="192" class="image_float_left" /> </td>    
    <td><strong>Does Physical Interpretability of Observation Map Improve the Photometric Stereo Network? </strong><br />
    <span id="ctl00_cph_paperSummary_gvPaperSummary_ctl05_PaperTitleLabel1"><span id="ctl00_cph_paperSummary_gvPaperSummary_ctl04_PaperTitleLabel2">  Satoshi Ikehata.  In proceedings of IEEE International Conference on Image Processing (ICIP), 2022. (<a href="ICIP2022_PS.pdf" target="_blank">paper</a>) </span></td>
</tr>

<tr>
    <td><img src="fig_icip2022_od.png" width="192" class="image_float_left" /> </td>
    <td><strong>Dual-ERP representation for Object Detection in 360 degree images. </strong><br />
    <span id="ctl00_cph_paperSummary_gvPaperSummary_ctl05_PaperTitleLabel1"><span id="ctl00_cph_paperSummary_gvPaperSummary_ctl04_PaperTitleLabel2">  Miao Cao, Satoshi Ikehata, Kiyoharu Aizawa.  In proceedings of IEEE International Conference on Image Processing (ICIP), 2022. </span></td>
</tr>


<tr>
    <td><img src="fig_cvpr2022.png" width="192" class="image_float_left" /> </td>
    <td><strong>Universal Photometric Stereo Network using Global Lighting Contexts. </strong><br />
    <span id="ctl00_cph_paperSummary_gvPaperSummary_ctl05_PaperTitleLabel1"><span id="ctl00_cph_paperSummary_gvPaperSummary_ctl04_PaperTitleLabel2">  Satoshi Ikehata.  In proceedings of CVF/IEEE Computer Vision and Pattern Recognition (CVPR), 2022 (<a href="cvpr2022/univps_cvpr2022.html" target="_blank">project site</a>). </span></td>
</tr>

<tr>
    <td><img src="pstransformer.jpg" width="192" class="image_float_left" /> </td>
    <td><strong>PS-Transformer: Learning Sparse Photometric Stereo Network using Self-Attention Mechanism. </strong><br />
    <span id="ctl00_cph_paperSummary_gvPaperSummary_ctl05_PaperTitleLabel1"><span id="ctl00_cph_paperSummary_gvPaperSummary_ctl04_PaperTitleLabel2">  Satoshi Ikehata.  In proceedings of British Machine Vision Conference (BMVC), 2021 (<a href="https://www.bmvc2021-virtualconference.com/assets/papers/0319.pdf" target="_blank">paper</a>, <a href="https://github.com/satoshi-ikehata/PS-Transformer-BMVC2021" target="_blank">github</a>). </span></td>
</tr>


<tr>
    <td><img src="pdot.jpg" width="192"  class="image_float_left" /> </td>
    <td><strong>Intersection Prediction from Single 360° Image via Deep Detection of Possible Direction of Travel.</strong><br />
    <span id="ctl00_cph_paperSummary_gvPaperSummary_ctl05_PaperTitleLabel1"><span id="ctl00_cph_paperSummary_gvPaperSummary_ctl04_PaperTitleLabel2">  Naoki Sugimoto, Satoshi Ikehata and Kiyoharu Aizawa.  In proceedings of
	  British Machine Vision Conference (BMVC), 2021 (<a href="https://www.bmvc2021-virtualconference.com/assets/papers/0423.pdf" target="_blank">paper</a>). </span></td>
</tr>
<tr>
    <td><img src="360sr.jpg" width="192" class="image_float_left" /> </td>
    <td><strong>360° Single Image Super Resolution via Distortion-Aware Network and Distorted Perspective Images.</strong><br />
    <span id="ctl00_cph_paperSummary_gvPaperSummary_ctl05_PaperTitleLabel1"><span id="ctl00_cph_paperSummary_gvPaperSummary_ctl04_PaperTitleLabel2">  Akito Nishiyama, Satoshi Ikehata, Kiyoharu Aizawa.  In proceedings of International Conference on Image Processing (ICIP), 2021 (<a href="https://ieeexplore.ieee.org/document/9506233" target="_blank">paper</a>). </span></td>
</tr>
<tr>
    <td><img src="fig_eccv2018.png" width="192" class="image_float_left" /> </td>
    <td><strong>CNN-PS: CNN-based Photometricc Stereo for General Non-Convex Surfaces. </strong><br />
    <span id="ctl00_cph_paperSummary_gvPaperSummary_ctl05_PaperTitleLabel1"><span id="ctl00_cph_paperSummary_gvPaperSummary_ctl04_PaperTitleLabel2">  Satoshi Ikehata.  In proceedings of European Conference on Computer Vision (ECCV), 2018 (<a href="https://github.com/satoshi-ikehata/CNN-PS" target="_blank">paper, supplementary, codes (github)</a>). </span></td>
</tr>
<tr>
    <td><img src="fig_mta2018.png" width="192" class="image_float_left" /> </td>
    <td><strong>Efficiency-enhanced cost-volume filtering featuring coarse-to-fine strategy.</strong><br />
    <span id="ctl00_cph_paperSummary_gvPaperSummary_ctl05_PaperTitleLabel1"><span id="ctl00_cph_paperSummary_gvPaperSummary_ctl04_PaperTitleLabel2"> Ryosuke Furuta, Satoshi Ikehata, Toshihiko Yamaskai, Kiyoharu Aizawa.  Multimedia Tools Appl. 77(10): 12469-12491, 2018 (<a href="https://link.springer.com/content/pdf/10.1007%2Fs11042-017-4897-1.pdf" target="_blank">paper</a>). </span></td>
</tr>
<tr>
    <td><img src="fig_eccv2018workshop.png" width="192"  class="image_float_left" /> </td>
    <td><strong>Scale Drift Correction of Camera Geo-Localization using Geo-Tagged Images</strong><br />
    <span id="ctl00_cph_paperSummary_gvPaperSummary_ctl05_PaperTitleLabel1"><span id="ctl00_cph_paperSummary_gvPaperSummary_ctl04_PaperTitleLabel2"> Kazuya Iwami, Satoshi Ikehata, Kiyoharu Aizawa. 6th Workshop on Computer Vision for Road Scene Understanding and Autonomous Driving (ECCV2018 Workshop), 2018 (<a href="https://arxiv.org/abs/1808.08544" target="_blank">preprint</a>). </span></td>
</tr>
<tr>
    <td><img src="fig_nips2017.png" width="192" height="99" class="image_float_left" /> </td>
    <td><strong>From Bayesian Sparsity to Gated Recurrent Nets</strong><br />
    <span id="ctl00_cph_paperSummary_gvPaperSummary_ctl05_PaperTitleLabel1"><span id="ctl00_cph_paperSummary_gvPaperSummary_ctl04_PaperTitleLabel2">Hao He, Bo Xin, Satoshi Ikehata, David P. Wipf. In proceedings of Neural Information Processing Systems（NIPS）, 2017 (accepted as an oral presentation, 1.20%): 5560-5570, 2017 (<a href="http://papers.nips.cc/paper/7139-from-bayesian-sparsity-to-gated-recurrent-nets" target="_blank">NIPS proceedings</a>). </span></td>
</tr>

<tr>
    <td><img src="fig_panosfm2016.png" width="192" height="99" class="image_float_left" /> </td>
    <td><strong>Panoramic Structure from Motion via Geometric Relationship Detection</strong><br />
    <span id="ctl00_cph_paperSummary_gvPaperSummary_ctl05_PaperTitleLabel1"><span id="ctl00_cph_paperSummary_gvPaperSummary_ctl04_PaperTitleLabel2">Satoshi Ikehata, Ivaylo Boyadzhiev, Qi Shan, Yasutaka Furukawa. CoRR abs/1612.01256, 2016 (<a href="https://arxiv.org/abs/1612.01256" target="_blank">arXiv paper</a>). </span></td>
</tr>
<tr>
    <td><img src="fig_iccv2015.png" width="192" height="99" class="image_float_left" /> </td>
    <td><strong>Structured Indoor Modeling </strong><br />
    <span id="ctl00_cph_paperSummary_gvPaperSummary_ctl05_PaperTitleLabel1"><span id="ctl00_cph_paperSummary_gvPaperSummary_ctl04_PaperTitleLabel2">Satoshi Ikehata, Hang Yan and Yasutaka Furukawa. In proceedings of IEEE International Conference on Computer Vision (ICCV), 2015 (accepted as an oral presentation, 3.30%) (<a href="https://www.cse.wustl.edu/~sikehata/sim/" target="_blank">project page</a>). </span></td>
</tr>
<tr>
    <td><img src="fig_icip2014.bmp" width="192"class="image_float_left" /> </td>
    <td><strong>Coarse-to-Fine Strategy for Efficient Cost-Volume Filtering</strong><br />
    <span id="ctl00_cph_paperSummary_gvPaperSummary_ctl05_PaperTitleLabel1"><span id="ctl00_cph_paperSummary_gvPaperSummary_ctl04_PaperTitleLabel2">Ryosuke Furuta, Satoshi Ikehata, Toshihiko Yamasaki and Kiyoharu Aizawa. In proceedings of IEEE International Conference on Image Procession(ICIP), 2014 (<a href="icip2014.pdf" target="_blank">paper</a>). </span></td>
  </tr>
<tr>
    <td><img src="fig_cvpr2014.png" width="192" class="image_float_left" /> </td>
    <td><strong>Photometric Stereo using Constrained Bivariate Regression for General Isotropic Surfaces</strong><br />
    <span id="ctl00_cph_paperSummary_gvPaperSummary_ctl05_PaperTitleLabel1"><span id="ctl00_cph_paperSummary_gvPaperSummary_ctl04_PaperTitleLabel2">Satoshi Ikehata and Kiyoharu Aizawa. In proceedings of Computer Vision and Pattern Recognition (CVPR), 2014 (accepted as an oral presentation, 5.76%) (<a href="CBRPScvpr2014.pdf" target="_blank">paper</a>, <a href="supp_cvpr2014.pdf" target="_blank">supplementary</a>, <a href="https://drive.google.com/open?id=1sTuxhKbgnd7iAsyFOKf5zCMEraORpwNx" target="_blank">source codes</a>). </span></td>
  </tr>
  <tr>
    <td><img src="fig_pami2014.png" width="192" class="image_float_left" /> </td>
    <td><strong>Photometric Stereo using Sparse Bayesian Regression for General Diffuse Surfaces</strong><br />
    <span id="ctl00_cph_paperSummary_gvPaperSummary_ctl05_PaperTitleLabel1"><span id="ctl00_cph_paperSummary_gvPaperSummary_ctl04_PaperTitleLabel2">Satoshi Ikehata, David Wipf, Yasuyuki Matsushita and Kiyoharu Aizawa. IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2014 (<a href="https://drive.google.com/open?id=1VetVYjmniOBBb4YY7xFdHxKAZ7WIkRIY" target="_blank">source codes</a>). </span></td>
  </tr>
  <tr>
    <td><img src="fig_icip2013.png" width="192" height="99" class="image_float_left" /> </td>
    <td><strong>Depth Map Inpainting and Super-Resolution based on Internal Statistics of Geometry and Appearance</strong><br />
    <span id="ctl00_cph_paperSummary_gvPaperSummary_ctl05_PaperTitleLabel1"><span id="ctl00_cph_paperSummary_gvPaperSummary_ctl04_PaperTitleLabel2">Satoshi Ikehata, Ji-Ho Cho and Kiyoharu Aizawa. In proceedings of IEEE International Conference on Image Procession(ICIP), 2013, (<a href="ICIP2013_SR_cm.pdf" target="_blank">pdf</a>). </span></td>
  </tr>
  <tr>
    <td><img src="fig_ivmsp2013.png" width="192" class="image_float_left" /> </td>
    <td><strong>Depth Map Upsampling using Cost-Volume Filtering</strong><br />
    <span id="ctl00_cph_paperSummary_gvPaperSummary_ctl05_PaperTitleLabel1"><span id="ctl00_cph_paperSummary_gvPaperSummary_ctl04_PaperTitleLabel2">Ji-Ho Cho, Satoshi Ikehata, Hyunjin Yoo, Margrit Gelautz and Kiyoharu Aizawa. In proceedings of 11th IEEE IVMSP Workshop: 3D Image/Video Technologies and Applications, 2013, (<a href="IVMSP2013_CR.pdf" target="_blank">pdf</a>). </span></td>
  </tr>
  <tr>
    <td><img src="fig_apsipa.png" width="192"  class="image_float_left" /> </td>
    <td><strong>Confidence-based Refinement of Corrupted Depth Maps</strong><br />
    <span id="ctl00_cph_paperSummary_gvPaperSummary_ctl05_PaperTitleLabel1"><span id="ctl00_cph_paperSummary_gvPaperSummary_ctl04_PaperTitleLabel2">Satoshi Ikehata and Kiyoharu Aizawa.    In proceedings of Signal & Information Processing Association Annual Summit and Conference (APSIPA ASC), 2012, (<a href="ikehata_apsipa2012.pdf" target="_blank">pdf</a>). </span></td>
  </tr>
  <tr>
    <td><img src="fig_cvpr2012.png" width="192"class="image_float_left" /> </td>
    <td><strong>Robust Photometric Stereo using Sparse Regression</strong><br />
    <span id="ctl00_cph_paperSummary_gvPaperSummary_ctl05_PaperTitleLabel1"><span id="ctl00_cph_paperSummary_gvPaperSummary_ctl04_PaperTitleLabel2">Satoshi Ikehata, David Wipf, Yasuyuki Matsushita, and Kiyoharu Aizawa. In proceedings of Computer Vision and Pattern Recognition (CVPR), 2012, (<a href="SBLPS_cvpr2012.pdf" target="_blank">pdf</a>, </span></span><a href="SBLPS-supp.pdf" target="_blank">supplementary</a>, <a href="https://drive.google.com/open?id=19IyBj3oynHXD7VQqX5BhG5l4lXlXhe4V" target="_blank">codes</a>).</td>
  </tr>
</table>

<h4>&nbsp;</h4>
  <!-- end .content --></div>
  <div class="footer">
    <p>COPYRIGHT 2013-2018, SATOSHI IKEHATA All Rights Reserved.</p>
  <!-- end .footer --></div>
<!-- end .container --></div>
</body>
</html>
